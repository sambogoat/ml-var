{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lr-var.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sambogoat/ml-var/blob/master/lr_var.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "q3T-vU4EjL_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class DataSet:\n",
        "\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.batch_no = 0\n",
        "        self.length = x.shape[0]\n",
        "\n",
        "    @staticmethod\n",
        "    def normalise_features(x):\n",
        "        mu = np.mean(x, axis=0)\n",
        "        sigma = np.std(x, axis=0)\n",
        "        return (x - mu) / sigma\n",
        "\n",
        "    def all_data(self, normalise=True):\n",
        "        if normalise:\n",
        "            return DataSet.normalise_features(self.x), self.y\n",
        "        else:\n",
        "            return self.x, self.y\n",
        "\n",
        "    def next_batch(self, size, normalise=True):\n",
        "        start = self.batch_no * size\n",
        "        end = start + size\n",
        "        self.batch_no += 1\n",
        "        if normalise:\n",
        "            return DataSet.normalise_features(self.x[start:end],), self.y[start:end]\n",
        "        else:\n",
        "            return self.x[start:end], self.y[start:end]\n",
        "\n",
        "\n",
        "class PPLs:\n",
        "    \"\"\"PPL training and test data\"\"\"\n",
        "\n",
        "    def __init__(self, size, error_frac):\n",
        "\n",
        "        with np.load(\"ppls_{}_{}.npz\".format(size, error_frac)) as f:\n",
        "            self.train = DataSet(f['x'], f['y'])\n",
        "\n",
        "        with np.load(\"ppls_{}_{}_test.npz\".format(size, error_frac)) as f:\n",
        "            self.test = DataSet(f['x'], f['y'])\n",
        "\n",
        "\n",
        "# #############\n",
        "# PPL Loader\n",
        "# #############\n",
        "def load_data(size, error_frac):\n",
        "    return PPLs(size, error_frac)\n",
        "\n",
        "\n",
        "# #############\n",
        "# PPL Generator\n",
        "# #############\n",
        "def generate_and_save_data(train_size, var_size, error_frac, is_test=False, decimals=4, high=100):\n",
        "\n",
        "    # The % of VaR errors\n",
        "    ok_error_split = int(train_size * error_frac)\n",
        "\n",
        "    # The VaR 'features' that represent an vector in error, i.e. first, middle and last\n",
        "    features_in_error = [0, int(var_size / 2), var_size-1]\n",
        "\n",
        "    ppls = np.around(np.random.uniform(low=1.0, high=high, size=(train_size, var_size)), decimals=decimals)\n",
        "\n",
        "    # Create the error ppls, i.e. setting the features to 0\n",
        "    error_ppls = ppls[0:ok_error_split]\n",
        "    for i in features_in_error:\n",
        "        error_ppls[:, i] = 0\n",
        "\n",
        "    # Error labels\n",
        "    error_labels = np.transpose(np.array([np.zeros(len(error_ppls), dtype=np.int32),\n",
        "                                          np.ones(len(error_ppls), dtype=np.int32)]))\n",
        "\n",
        "    # Valid ppls and labels, i.e. 1.\n",
        "    good_ppls = ppls[ok_error_split:len(ppls)]\n",
        "    good_labels = np.transpose(np.array([np.ones(len(good_ppls), dtype=np.int32),\n",
        "                                         np.zeros(len(good_ppls), dtype=np.int32)]))\n",
        "\n",
        "    # Concatenate the two arrays and shuffle maintaining relative ordering between ppls and labels.\n",
        "    all_x = np.concatenate((good_ppls, error_ppls))\n",
        "    all_y = np.concatenate((good_labels, error_labels))\n",
        "    perm = np.random.permutation(train_size)\n",
        "    all_x_shuffled = all_x[perm]\n",
        "    all_y_shuffled = all_y[perm]\n",
        "    assert np.array_equal(np.where(np.amin(all_x_shuffled, axis=1) == 0)[0], np.where(all_y_shuffled[:, 1] == 1)[0])\n",
        "\n",
        "    if is_test:\n",
        "        file = \"ppls_{}_{}_test.npz\".format(var_size, error_frac)\n",
        "    else:\n",
        "        file = \"ppls_{}_{}.npz\".format(var_size, error_frac)\n",
        "\n",
        "    np.savez(file, x=all_x_shuffled, y=all_y_shuffled)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}